{
    "name": "LeiJohn",
    "personal background": "<Lei Zhang is a Chair Professor of Computer Vision and Image Analysis at The Hong Kong Polytechnic University, Fellow of IEEE, and has been involved with OPPO Research Institute. He holds a PhD degree from Northwestern Polytechnical University, M.Sc from the same institution, and B.Sc from Shenyang Inst. of Aeronautical Engineering. Zhang's work experience includes being an Assistant Professor at Hong Kong Polytechnic University from 2003-2006, Associate Professor from 2010-2015, Professor from 2015-2017, and Chair Professor since 2017. He was also a Postdoctoral Fellow at McMaster University, Canada from 2001-2003.> < researcher's background information not found for any of the researchers >",
    "research interest": "> Visual Computing Lab (our mission): Y learning and beyond: for future visual enhancement and understanding.\n> \n> Visual Computing Lab (our mission): Y learning and beyond: for future visual enhancement and understanding.\n\n> Papers&Codes News 1. Several Postdoctoral Fellow or Research Associate positions on Video Generation and Vision-Language Models are available. Please send me your CV if you have interest.News 1. Several Postdoctoral Fellow or Research Associate positions on Video Generation and Vision-Language Models are available. Please send me your CV if you have interest.\n> \n> Papers&Codes News 2. Several PhD Student positions jointly trained with OPPO Research Institute are available. The research topics include Image/Video Restoration/Enhancement, Diffusion Models, Vision-Language Models, Efficient Network Architectures, etc . Please send me your CV if you have interest. \n> \n> Papers&Codes News 3. Research Interns on Image Enhancement, Diffusion Models, Vision-Language Models, etc., are available at OPPO Research Institute . Please send me your CV if you have interest.\n> \n> Newly accepted NeurIPS 2024. ( High quality and stable super-resolution in just one step diffusion! )\n> \n> G. Zhang, L. Fan, C. He, Z. Lei, Z. Zhang, L. Zhang, \"Voxel Mamba: Group-Free State Space Models for Point Cloud based 3D Object Detection,\" inNeurIPS2024 ( spotlight ). ( New SOTA on point cloud 3D detection! )\n> \n> Y. Zhang, L. Zhang, \"AdaNeg: Adaptive Negative Proxy Guided OOD Detection with Vision-Language Models,\" inNeurIPS2024.\n> \n> D. Chen, Z. Zhang, J. Liang, L. Zhang, \"SSL: A Self-similarity Loss for Improving Generative Image Super-resolution,\" in ACM MM 2024. ( A simple yet effective loss for generative SR! )\n> \n> C. Xiao, M. Li, Z. Zhang, D. Meng, L. Zhang, \"Spatial-Mamba: Effective Visual State Space Models via Structure-Aware State Fusion,\" preprint. ( A real visual Mamba model, you just need to scan once! )2.\n> \n> Z. Zhang, R. Li, L. Zhang, \"FreCaS: Efficient Higher-Resolution Image Generation via Frequency-aware Cascaded Sampling,\" preprint. ( Generating higher-resolution images better and faster! )\n> \n> X. Kong, K. Huang, P. Li, L. Zhang, \"Toward Generalizing Visual Brain Decoding to Unseen Subjects,\" preprint. ( Can visual brain encoding be generalized? )3.\n> \n> M. Ni, Y. Fan, L. Zhang, W. Zuo, \"Visual-O1: Understanding Ambiguous Instructions via Multi-modal Multi-turn Chain-of-thoughts \"TokenPacker: Efficient Visual Projector for Multimodal LLM\"",
    "publication": "Title: Newly accepted NeurIPS 2024.\nPublished Time: Not available\nConference: NeurIPS 2024\n\nNewly accepted papers:\n\n1. Voxel Mamba: Group-Free State Space Models for Point Cloud based 3D Object Detection in NeurIPS2024 (spotlight)\n   New SOTA on point cloud 3D detection!\n\n2. AdaNeg: Adaptive Negative Proxy Guided OOD Detection with Vision-Language Models in NeurIPS2024\n   New SOTA on OOD detection!\n\n3. SSL: A Self-similarity Loss for Improving Generative Image Super-resolution in ACM MM 2024\n   A simple yet effective loss for generative SR!\n\nPreprints:\n\n1. Spatial-Mamba: Effective Visual State Space Models via Structure-Aware State Fusion (paper) (code)\n   A real visual Mamba model, you just need to scan once!\n\n2. FreCaS: Efficient Higher-Resolution Image Generation via Frequency-aware Cascaded Sampling (paper) (code)\n   Generating higher-resolution images better and faster!\n\n3. Toward Generalizing Visual Brain Decoding to Unseen Subjects (paper) (code)\n   Can visual brain encoding be generalized?\n\n4. Visual-O1: Understanding Ambiguous Instructions via Multi-modal Multi-turn Chain-of-thoughts Reasoning (paper) (code)\n   Multi-view consistent 3D scene editing!\n\n5. TokenPacker: Efficient Visual Projector for Multimodal LLM (paper) (code)\n   Up to 89% visual token compression!\n\n6. SyncNoise: Geometrically Consistent Noise Prediction for Text-based 3D Scene Editing (paper) (code)\n   Multi-view consistent 3D scene editing!\n\n7. Improving the Stability of Diffusion Models for Content Consistent Super-Resolution (paper) (code)\n   \n\n8. Towards Effective Multiple-in-One Image Restoration: A Sequential and Prompt Learning Strategy (paper) (code&data)\n   ",
    "recruitment": "* Researcher's Recruitment Information:\n    + Postdoctoral Fellow or Research Associate positions on Video Generation and Vision-Language Models are available.\n    + PhD Student positions jointly trained with OPPO Research Institute are available.\n    + Research Interns on Image Enhancement, Diffusion Models, Vision-Language Models, etc., are available at OPPO Research Institute.\n\n* Salary: No salary information is mentioned in the input text.\n\n* Lab Condition: The Visual Computing Lab's mission is \"Y learning and beyond: for future visual enhancement and understanding.\" * No relevant information found about researcher's recruitment information.\n* No relevant information found about salary.\n* Lab condition:\n  + Spatial-Mamba: Effective Visual State Space Models via Structure-Aware State Fusion \n  + FreCaS: Efficient Higher-Resolution Image Generation via Frequency-aware Cascaded Sampling \n  + Toward Generalizing Visual Brain Decoding to Unseen Subjects \n  + Visual-O1: Understanding Ambiguous Instructions via Multi-modal Multi-turn Chain-of-thoughts Reasoning \n  + TokenPacker: Efficient Visual Projector for Multimodal LLM \n  + SyncNoise: Geometrically Consistent Noise Prediction for Text-based 3D Scene Editing \n  + Improving the Stability of Diffusion Models for Content Consistent Super-Resolution \n  + Towards Effective Multiple-in-One Image Restoration: A Sequential and Prompt Learning Strategy"
}