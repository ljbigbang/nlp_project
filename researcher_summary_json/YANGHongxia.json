{
    "name": "YANGHongxia",
    "personal background": "<Dr. Hongxia Yang, PhD from Duke University, has published over 100 papers in top-tier conferences and journals, and holds more than 50 patents in the USA and China. Previously, she worked as a research staff member at IBM T.J. Watson research center, principal scientist at Yahoo!, an AI scientist and Director at Alibaba DAMO Academy, an adjunct professor at Zhejiang University’s Shanghai Advanced Research Institute and the Head of Large Language Models at ByteDance US.</self-funded> <Researchers Background>\n\n* Haiteng Zhao \n* Chang Ma \n* Guoyin Wang \n* Jing Su \n* Lingpeng Kong \n* Jingjing Xu \n* Zhi-Hong Deng \n* Hongxia Yang \n\nNote: The researchers' background information is not provided in the input text.",
    "research interest": "• For Ultra-Large Scale High-Performance Graph Neural Network Computing Platform and Its Applications(Second Contributor, jointly applied with Zhejiang University).\n• Large-Scale Graph Neural Network Edge-Cloud Collaborative Computing Platform and Application Demonstration (Third Contributor, jointly applied with Zhejiang University).",
    "publication": "<font size=\"5\">Title: Dr. Hongxia Yang - Researcher</font>\n<p>Dr. Hongxia Yang, PhD from Duke University, has published over 100 papers in top-tier conferences and journals, and holds more than 50 patents in the USA and China.</p>\n\n<p>Previously, she worked as a research staff member at IBM T.J. Watson research center, principal scientist at Yahoo!, an AI scientist and Director at Alibaba DAMO Academy, an adjunct professor at Zhejiang University’s Shanghai Advanced Research Institute and the Head of Large Language Models at ByteDance US.</p>\n\n<font size=\"4\">Open Positions:</font>\n<p>I am currently seeking to recruit fully funded Ph.D. students and postdocs who are interested in specializing in Generative AI and decentralized computing. Please feel free to send me an email with your CV. Self-funded visiting students and scholars are also welcome to apply.</p>\n\n<font size=\"3\">Selected Publications:</font>\n<p>1. InfiBench: Evaluating the Question-Answering Capabilities of Code Large Language Models, Linyi Li, Shijie Geng, Zhenwen Li, Yibo He, Hao Yu, Ziyue Hua, Guanghan Ning, Siwei Wang, Tao Xie,Hongxia Yang, NeurIPS, 2024.</p>\n<p>2. DreamClear: High-Capacity Real-World Image Restoration with Privacy-Safe Dataset Curation, Yuang Ai, Xiaoqiang Zhou, Huaibo Huang, Xiaotian Han, Zhengyu Chen, Quanzeng You,Hongxia Yang, NeurIPS, 2024.</p>\n<p>3. Visual Anchors Are Strong Information Aggregators For Multimodal Large Language Model, Haogeng Liu, Quanzeng You, Xiaotian Han, Yongfei Liu, Huaibo Huang, Ran He,Hongxia Yang, NeurIPS, 2024.</p>\n<p>4. Empowering Large Language Model Agents through Action Learning, Haiteng Zhao, Chang Ma, Guoyin Wang, Jing Su, Lingpeng Kong, Jingjing Xu, Zhi-Hong Deng,Hongxia Yang, COLM, 2024.</p>\n<p>5. An Expert is Worth One Token: Synergizing Multiple Expert LLMs as Generalist via Expert Token Routing, Ziwei Chai, Guoyin Wang, Jing Su, Tianjie Zhang, Xuanwen Huang, Xuwu Wang, Jingjing Xu, Jianbo Yuan,Hongxia Yang, Fei Wu, Yang Yang, ACL, 2024.</p>\n<p>6. DeVAn: Dense Video Annotation for Video-Language Models, Tingkai Liu, Yunzhe Tao, Haogeng Liu, Qihang Fang, Ding Zhou, Huaibo Huang, Ran He,Hongxia Yang, ACL, 2024.</p>\n<p>7. Expedited Training of Visual Conditioned Language Generation via Redundancy Reduction, Yiren Jian, Tingkai Liu, Yunzhe Tao, Chunhui Zhang, Soroush Vosoughi,Hongxia Yang, ACL, 2024.</p>\n<p>8. InfiMM: Advancing Multimodal Understanding with an Open-Sourced Visual Language Model, Haogeng Liu, Quanzeng You, Yiqi Wang, Xiaotian Han, Bohan Zhai, Yongfei Liu, Wentao Chen, Yiren Jian, Yunzhe Tao, Jianbo Yuan, Ran He,Hongxia Yang, ACL, 2024.</p>\n<p>9. LoraRetriever: Input-Aware LoRA Retrieval and Composition for Mixed Tasks in the Wild, Ziyu Zhao, Leilei Gan, Guoyin Wang, Wangchunshu Zhou,Hongxia Yang, Kun Kuang, Fei Wu, ACL, 2024.</p> Title: Two Stones Hit One Bird: Bilevel Positional Encoding for Better Length Extrapolation\nPublished Time: ICML, 2024.\n\nSelf-Infilling Code Generation\nLin Zheng, Jianbo Yuan, Zhi Zhang, Hongxia Yang, Lingpeng Kong\nICML, 2024.\n\nSelf-Infilling Code Generation\nLin Zheng, Jianbo Yuan, Zhi Zhang, Hongxia Yang, Lingpeng Kong\nICML, 2024.\n\nInfiAgent-DABench: Evaluating Agents on Data Analysis Tasks\nXueyu Hu, Ziyu Zhao, Shuang Wei, Ziwei Chai, Qianli Ma, Guoyin Wang, Xuwu Wang, Jing Su, Jingjing Xu, Ming Zhu, Yao Cheng, Jianbo Yuan, Jiwei Li, Kun Kuang, Yang Yang, Hongxia Yang, Fei Wu\nICML, 2024.\n\n$\\mathcal{\\beta}$-Coder: Value-Based Deep Reinforcement Learning for Program Synthesis\nZishun Yu, Yunzhe Tao, Liyu Chen, Tao Sun, Hongxia Yang\nICLR, 2024.\n\nLEMON: Lossless model expansion\nYite Wang, Jiahao Su, Hanlin Lu, Cong Xie, Tianyi Liu, Jianbo Yuan, Haibin Lin, Ruoyu Sun, Hongxia Yang\nICLR, 2024.\n\nLearning Stackable and Skippable LEGO Bricks for Efficient, Reconfigurable, and Variable-Resolution Diffusion Modeling\nHuangjie Zheng, Zhendong Wang, Jianbo Yuan, Guanghan Ning, Pengcheng He, Quanzeng You, Hongxia Yang, Mingyuan Zhou\nICLR, 2024.\n\nLet Models Speak Ciphers: Multiagent Debate through Embeddings\nChau Pham, Boyi Liu, Yingxiang Yang, Zhengyu Chen, Tianyi Liu, Jianbo Yuan, Bryan A. Plummer, Zhaoran Wang, Hongxia Yang\nICLR, 2024.",
    "recruitment": "<Open positions: I am currently seeking to recruit fully funded Ph.D. students and postdocs who are interested in specializing in Generative AI and decentralized computing. Please feel free to send me an email with your CV. Self-funded visiting students and scholars are also welcome to apply>\n\n<Salary not mentioned>\n\n<Lab conditions not mentioned> • LoraRetriever: Input-Aware LoRA Retrieval and Composition for Mixed Tasks in the Wild, Ziyu Zhao, Leilei Gan, Guoyin Wang, Wangchunshu Zhou,Hongxia Yang, Kun Kuang, Fei Wu, ACL, 2024. - No relevant content.\n\n• Self-Infilling Code Generation, Lin Zheng, Jianbo Yuan, Zhi Zhang,Hongxia Yang, Lingpeng Kong, ICML, 2024. - \n    - Position: Nanyang Institute of Technology\n    - Recruitment Information: No available information.\n    - Salary: No available information.\n    - Lab Condition: No available information.\n\n• Self-Infilling Code Generation, Lin Zheng, Jianbo Yuan, Zhi Zhang,Hongxia Yang, Lingpeng Kong, ICML, 2024. - (same as above)\n\n• LEMON: Lossless model expansion, Yite Wang, Jiahao Su, Hanlin Lu, Cong Xie, Tianyi Liu, Jianbo Yuan, Haibin Lin, Ruoyu Sun,Hongxia Yang, ICLR, 2024. - \n    - Position: Nanyang Institute of Technology\n    - Recruitment Information: No available information.\n    - Salary: No available information.\n    - Lab Condition: No available information.\n\n• Learning Stackable and Skippable LEGO Bricks for Efficient, Reconfigurable, and Variable-Resolution Diffusion Modeling, Huangjie Zheng, Zhendong Wang, Jianbo Yuan, Guanghan Ning, Pengcheng He, Quanzeng You,Hongxia Yang, Mingyuan Zhou, ICLR, 2024. - \n    - Position: Nanyang Institute of Technology\n    - Recruitment Information: No available information.\n    - Salary: No available information.\n    - Lab Condition: No available information.\n\n• LoraRetriever: Input-Aware LoRA Retrieval and Composition for Mixed Tasks in the Wild, Ziyu Zhao, Leilei Gan, Guoyin Wang, Wangchunshu Zhou,Hongxia Yang, Kun Kuang, Fei Wu, ACL, 2024. - (same as above)"
}