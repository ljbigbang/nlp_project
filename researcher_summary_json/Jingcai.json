{
    "name": "Jingcai",
    "personal background": "< Researchers Background >\nCurrently a Research Assistant Professor at Department of Computing, Kowloon, Hong Kong SAR. Successfully defended Ph.D. degree in Dec. 2020. Prior to that, received M.E. and B.E. degrees from Japan and China, respectively, both in Computer Science and AI/ML.\n\nPreviously held the position of Postdoctoral Research Fellow at Australia from 2021 to 2022. Concurrently served as an Associate Professor with School of Computing and Artificial Intelligence, China.\n\nSpent nearly 2 years in investment banking industry after Waseda University.\n\nHas a strong background in Computer Science and AI/ML with experience in research and academia.\n\n <Relevant Work Experience> <Research Background>\n  2017-2021: Ph.D., The Hong Kong Polytechnic University, Hong Kong (Supervisor:Prof. Song Guo, now HKUST)\n  2019-2020: Visiting Ph.D., University of Sydney, Australia (Supervisor:Prof. Dacheng Tao, now NTU)\n  2013-2015: M.E., Waseda University, Japan (Supervisor:Prof. Takayuki Furuzuki)\n  2009-2013: B.E., Sichuan University, China <content>\nResearcher Jingming Liang is an alumna of HUST (Huston University) with a background as a research assistant from 2023 to 2024. She is currently a Ph.D. student at the University of Iowa, USA.\n</content> • Q. Guo is an author of multiple research papers in various fields such as Neural Information Processing Systems (NeurIPS), European Conference on Computer Vision (ECCV), and AAAI Conference on Artificial Intelligence.\n \nNote: The content about researcher's background could not be found from the input as it was mentioned only once that Q. Guo is an author of multiple research papers, but the actual details about his background were not provided. # Research Background \nThe researcher's background information isn't explicitly mentioned on this webpage. However, we can identify some commonalities among their works.\n\nTheir research focuses primarily on the topic of Federated Learning (FL). This is indicated by the many conferences they presented papers at involving the IEEE/CVF Conference on Computer Vision and Pattern Recognition(CVPR), International Joint Conference on Neural Networks(IJCNN) and others, that have FL-related topics in them. <Researcher's Background>\n- Z. Liu is a researcher and has co-authored papers on image-based visual perception, including a book titled \"Machine Learning on Commodity Tiny Devices\" with J. Guo.\n \n<Researcher's Experience>\n- J. Guo has taught courses on internet infrastructure and protocols at PolyU in Spring 2024, data structures and database systems at PolyU in Spring 2023, and data structures three times at SWUFE in Fall 2021.\n- J. Guo is also involved in serving as a senior PC for the 39th Annual AAAI Conference on Artificial Intelligence (AAAI2025), a session chair for the 33rd International Joint Conference on Artificial Intelligence (IJCAI2024), and a track chair (TPC Vice-Chair) for the 100th IEEE Vehicular Technology Conference. • Area Chair:The 41st International Conference on Machine Learning (ICML2024)\n• Area Chair:The 32nd ACM International Conference on Multimedia (ACM-MM2024)\n• Session Chair:The 98th IEEE Vehicular Technology Conference (VTC2023 Fall)\n• Publicity Chair:The 41st IEEE International Symposium on Reliable Distributed Systems (SRDS2022)\n• Session Chair:The 23th IEEE International Conference on Multimedia and Expo (ICME2022)",
    "research interest": "Low-shot AI, learning/modeling with limited resources in terms of data, computing capability, and their derivative applications beneficial from theory to practice.\n\nSpecific topics include zero/few-shot learning, federated learning, representation learning, model compression, and lightweight deployment/training of foundation models. No relevant content found.",
    "publication": "<title>Low-Shot AI</title>\n<p_published time=\"2024.01\">Congratulations to Zhijie Raofor being granted the Ph.D. offer from PolyU.</p>\n<p_published time=\"2023.12\">Congratulations to Miaoge Li and Yang Chen for being granted the Ph.D. offers from PolyU.</p>\n<conference> \n    <p_published time=\"2024.08\">Serve as Senior Program Committee for AAAI 2025.</p>\n    <p_published time=\"2024.08\">Serve as Session Chair (multimodal learning) for IJCAI 2024.</p>\n    <p_published time=\"2024.07\">One General Research Fund (GRF) has been granted by Research Grants Council (RGC) of Hong Kong.</p>\n    <p_published time=\"2024.03\">Serve as Track Chair (TPC Vice-Chair) for VTC 2024-Fall.</p>\n    <p_published time=\"2024.01\">Serve as Area Chair for ICML 2024.</p>\n    <p_published time=\"2024.01\">Serve as Area Chair for ACM-MM 2024.</p>\n</conference>\n\n<grant>\n<p_published time=\"2024.07\">One General Research Fund (GRF) has been granted by Research Grants Council (RGC) of Hong Kong.</p>\n<p_published time=\"2017\">Recipient of the Hong Kong PhD Fellowship Scheme (HKPFS) supported by Hong Kong RGC.</p>\n</grant>\n\n<Editorship>\n    <p_published time=\"2023.12\">Serve as Associate Editor for IEEE Open Journal of the Computer Society (IEEE OJ-CS).</p>\n    <p_published time=\"2023.10\">Serve as Session Chair for VTC 2023.</p>\n    <p_published time=\"2023.09\">Serve as Guest Editor for IEEE Transactions on Computational Social Systems (IEEE TCSS) (Special Issue on Few-shot/Zero-shot Learning for Knowledge Discovery in Social Networks).</p>\n</Editorship> <title>Selected Publications</title>\n<p>Published at:</p>\n\n<ol style=\"list-style-type:upper-alpha;\">\n    <li>International Joint Conference on Artificial Intelligence (IJCAI, CCF-A/Core-A*) 2024</li>\n    <li>ACM International Conference on Multimedia (ACM-MM, CCF-A/Core-A*) 2024</li>\n    <li>International Conference on Machine Learning (ICML, CCF-A/Core-A*) 2024</li>\n    <li>Annual Conference on Neural Information Processing Systems (NeurIPS, CCF-A/Core-A*) 2024</li>\n    <li>IEEE Transactions on Computational Social Systems (TCSS) 2024</li>\n</ol>\n\n<ol style=\"list-style-type:lower-alpha;\">\n    <li>ParsNets: A Parsimonious Composition of Orthogonal and Low-Rank Linear Networks for Zero-Shot Learning</li>\n    <li>Dual Expert Distillation Network for Generalized Zero-Shot Learning</li>\n    <li>Fine-Grained Side Information Guided Dual-Prompts for Zero-Shot Skeleton Action Recognition</li>\n    <li>SFP: Spurious Feature-Targeted Pruning for Out-of-Distribution Generalization</li>\n    <li>FreePIH: Training-Free Painterly Image Harmonization with Diffusion Model</li>\n    <li>Causally Motivated Personalized Federated Invariant Learning with Shortcut-Averse Information-Theoretic Regularization</li>\n    <li>Geometry Awakening: Cross-Geometry Learning Exhibits Superiority over Individual Structures</li>\n    <li>CGraphNet: Contrastive Graph Context Prediction for Sparse Unlabeled Short Text Representation Learning on Social Media</li>\n    <li>A Review of Few-shot and Zero-shot Learning for Node Classification in Social Networks</li>\n    <li>Vision-Language Meets the Skeleton: Progressively Distillation with Cross-Modal Knowledge for 3D Action Representation</li>\n    <li>Model Decomposition and Reassembly for Purified Knowledge Transfer in Personalized Federated Learning</li>\n</ol> Title: Personalized Federated Domain-Incremental Learning Based on Adaptive Knowledge Matching\nPublished Time: In press\nConference: IEEE Transactions on Mobile Computing (TMC), IF=7.7/JCR-Q1, 2024.\n\nTitle: Multi-modal Dual-embedding Networks for Malware Open-set Recognition\nPublished Time: DOI:10.1109/TNNLS.2024.3373809\nConference: IEEE Transactions on Neural Networks and Learning Systems (TNNLS), IF=14.255/JCR-Q1, 2024.\n\nTitle: Semantic Reasoning with Compound Domains for Single-Domain Generalized Object Detection\nPublished Time: Accept\nConference: IEEE Transactions on Neural Networks and Learning Systems (TNNLS), IF=14.255/JCR-Q1, 2024.\n\nTitle: Data Quality-aware Mixed-precision Quantization via Hybrid Reinforcement Learning\nPublished Time: DOI:10.1109/TNNLS.2024.3409692\nConference: IEEE Transactions on Neural Networks and Learning Systems (TNNLS), IF=14.255/JCR-Q1, 2024.\n\nTitle: Unveiling User Interests: A Deep User Interest Exploration Network for Sequential Location Recommendation\nPublished Time: DOI:10.1016/J.INS.2024.121416\nConference: Information Sciences (INS), IF=8.1/JCR-Q1, 2024.\n\nTitle: On the Robustness of Neural-enhanced Video Streaming Against Adversarial Attacks\nPublished Time: DOI:10.1109/AAAI.2024.3350380\nConference: AAAI Conference on Artificial Intelligence, CCF-A/Core-A*, 2024.\n\nTitle: Progressive Cross-primitive Compatibility for Open-World Compositional Zero-Shot Learning\nPublished Time: DOI:10.1109/AAAIAAAI.2024.3409692\nConference: AAAI Conference on Artificial Intelligence, CCF-A/Core-A*, 2024.\n\nTitle: Non-Exemplar Online Class-incremental Continual Learning via Dual-prototype Self-augment and Refinement\nPublished Time: DOI:10.1109/AAAIAAAI.2024.3350380\nConference: AAAI Conference on Artificial Intelligence, CCF-A/Core-A*, 2024.\n\nTitle: Patch Automatic Skip Scheme for Efficient On-device Video Perception\nPublished Time: DOI:10.1109/TPAMI.2024.3350380\nConference: IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), IF=24.314/JCR-Q1, 2024.\n\nTitle: Learning Personalized Causally Invariant Representations for Heterogeneous Federated Clients\nPublished Time: ICLR 2024\nConference: International Conference on Learning Representations, CCF-A/Core-A*, 2024.\n\nTitle: Disentangled Prompt Tuning for Multiple Latent Domain Generalization in Federated Learning\nPublished Time: DOI:10.1109/CVPR.2024.3350380\nConference: IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), CCF-A/Core-A*, 2024.\n\nTitle: Bridging the Modality Gap for Cross-Modal Knowledge Distillation\nPublished Time: DOI:10.1109/CVPR.2024.3409692\nConference: IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), CCF-A/Core-A*, 2024. <Title Zero-Shot Learning as Sample-Level Graph Recognition</Title>\n<Published Time>2023</Published Time>\n<Conference>AAAI Conference on Artificial Intelligence(AAAI, CCF-A/Core-A*)</Conference>\n\n<Content -(ML)$^2$P-Encoder: On Exploration of Channel-Class Correlation for Multi-Label Zero-Shot Learning,Z. Liu, S. Guo, X. Lu,J. Guo#, J. Zhang, Y. Zeng, F. Huo,IEEE/CVF Conference on Computer Vision and Pattern Recognition(CVPR, CCF-A/Core-A*),2023. • -Decomposed Soft Prompt Guided Fusion Enhancing for Compositional Zero-Shot Learning,X. Lu, S. Guo, Z. Liu,J. Guo#,IEEE/CVF Conference on Computer Vision and Pattern Recognition(CVPR, CCF-A/Core-A*),2023. • -Towards Data-Independent Knowledge Transfer in Model-Heterogeneous Federated Learning,J. Zhang, S. Guo,J. Guo#, D. Zeng, J. Zhou, A. Zomaya,IEEE Transactions on Computers(TC, CCF-A, DOI:10.1109/TC.2023.3272801),2023.• -UTDNet: A Unified Triplet Decoder Network for Multimodal Salient Object Detection,F. Huo, Z. Liu,J. Guo#, W. Xu, S. Guo,Neural Networks(NN, IF=9.657/JCR-Q1, DOI:10.1016/j.neunet.2023.11.051),2023. • -Towards performance-maximizing neural network pruning via global channel attention,Y. Wang, S. Guo,J. Guo, J. Zhang, W. Zhang, C. Yan, Y. Zhang,Neural Networks(NN, IF=9.657/JCR-Q1, DOI:10.1016/j.neunet.2023.11.065),2023. • -Hwamei: A Learning-Based Synchronization Scheme for Hierarchical Federated Learning,T. Qi, Y. Zhan, P. Li,J. Guo, Y. Xia,IEEE International Conference on Distributed Computing Systems(ICDCS, CCF-B/Core-A),2023. • -Towards Fairer and More Efficient Federated Learning via Multidimensional Personalized Edge Models,Y. Wang,J. Guo, J. Zhang, S. Guo, W. Zhang, Q. Zheng,International Joint Conference on Neural Networks(IJCNN, Core-B),2023.• -Personalized Federated Learning with Contextualized Generalization,X. Tang, S. Guo,J. Guo#,International Joint Conference on Artificial Intelligence(IJCAI, CCF-A/Core-A*),2022. • -Towards Unbiased Multi-Label Zero-Shot Learning with Pyramid and Semantic Attention,Z. Liu, S. Guo,J. Guo#, Y. Xu, F. Huo,IEEE Transactions on Multimedia(TMM, IF=8.4/JCR-Q1, DOI:10.1109/TMM.2022.3222657),2022. • -Conservative Novelty Synthesizing Network for Malware Recognition in an Open-Set Scenario,J. Guo, S. Guo, S. Ma, Y. Sun, Y. Xu,IEEE Transactions on Neural Networks and Learning Systems(TNNLS, IF=14.255/JCR-Q1, DOI:10.1109/TNNLS.2021.3099122),2021.(Outstanding Paper Award ofGDCA) • -INT8 Training with Loss-Aware Compensation and Backward Quantization for Tiny On-Device Learning,Q. Zhou, S. Guo, Z. Qu,J. Guo, Z. Xu, J. Zhang, T. Guo, B. Luo, J. Zhou,USENIX Annual Technical Conference(USENIX-ATC, CCF-A/Core-A*),2021.• -On-Device Learning Systems for Edge Intelligence: A Software and Hardware Synergy Perspective,Q. Zhou, Z. Qu, S. Guo, B. Luo,J. Guo, Z. Xu, R. Akerkar,IEEE Internet of Things Journal(IoT-J, IF=10.6/JCR-Q1, DOI:10.1109/JIOT.2021.3063147),2021. • -Dual-View Attention Networks for Single Image Super-Resolution,J. Guo, S. Ma, J. Zhang, Q. Zhou, S. Guo,ACM International</Content> • Title: A Novel Perspective to Zero-Shot Learning: Towards an Alignment of Manifold Structures via Semantic Feature Expansion\nPublished Time: 2020\nConference: ACM-MM, CCF-A/Core-A*\n\n• Title: Adaptive Adjustment with Semantic Feature Space for Zero-Shot Recognition\nPublished Time: 2019\nConference: IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)\nCCF-B/Core-B\n\n• Title: Adaptive Adjustment with Semantic Feature Space for Zero-Shot Recognition\nPublished Time: 2019\nConference: IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)\nCCF-B/Core-B\n\n• Title: EE-AE: An Exclusivity Enhanced Unsupervised Feature Learning Approach\nPublished Time: 2019\nConference: IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)\nCCF-B/Core-B\n\n• Title: AMS-SFE: Towards an Alignment of Manifold Structures via Semantic Feature Expansion for Zero-Shot Learning\nPublished Time: 2019\nConference: IEEE International Conference on Multimedia and Expo (ICME)\nCCF-B/Core-A\n\n• Title: An improved incremental training approach for large-scaled dataset based on support vector machine\nPublished Time: 2016\nConference: IEEE/ACM International Conference on Big Data Computing, Applications and Technologies (BDCAT) Title: \n- ACM International Conference on Multimedia\n- International Conference on Machine Learning\n- IEEE International Conference on Acoustics, Speech, and Signal Processing\n- European Conference on Computer Vision\n- IEEE International Conference on Multimedia and Expo\n- International Joint Conference on Neural Networks\n- IEEE International Conference on Big Data Intelligence and Computing\n\nPublished Time: \n- 2022\n- 2023 / 2024\n- 2019 / 2020 / 2021\n- 2022 / 2023 / 2024\n- 2018\n\nConference of Researcher's Publication:\nACM-MM: 2022\nICML: 2022\nICASSP: 2023 \nECCV: 2022 / 2024\nICME: 2019 / 2020 / 2021\nIJCNN: 2022 / 2023 / 2024\nDataCom: 2018",
    "recruitment": "<h3>Research Assistant Professor</h3>\n<p>Kowloon, Hong Kong SAR<br>\nCOMP, PolyU<br>\nEmail<br>\nLinkedIn<br>\nGoogle Scholar</p>\n\n<h3>Eligible to hire/supervise</h3>\n<ol>\n  <li>Ph.D.</li>\n  <li>Postdoc</li>\n  <li>RA (Research Assistant)</li>\n</ol>\n\n<h2>Salary Information</no content found</h2>\n\n<h2>Lab Condition Information</no content found</h2> <Researcher's Recruitment Information>\n* Fully funded openings for PhD Student, Postdoctoral Researcher, and Research Assistant\n* Interested candidates can drop an email to jc-jingcai.guo@polyu.edu.hk with complete CV\n* Candidates with strong programming and mathematics backgrounds are preferred\n\n<Salary Information>\n* No specific salary information is mentioned in the input.\n\n<Lab Condition Information>\n* The lab has fully funded openings for PhD Student, Postdoctoral Researcher, and Research Assistant\n* The lab is located at The Hong Kong Polytechnic University <Researcher's Recruitment Information:\n- Chief Supervisor: [Placement: Ph.D. Student, University of Iowa, USA.]>\n\n<Salary:>\n- No relevant salary information is available.\n\n<Lab Condition:>\n- No relevant lab condition information is available.> • -CGraphNet: Contrastive Graph Context Prediction for Sparse Unlabeled Short Text Representation Learning on Social Media: \n    Salaries: None mentioned.\n    Lab condition: None mentioned.\n\n• -A Review of Few-shot and Zero-shot Learning for Node Classification in Social Networks:\n    Salaries: None mentioned.\n    Lab condition: None mentioned.\n\n• -Vision-Language Meets the Skeleton: Progressively Distillation with Cross-Modal Knowledge for 3D Action Representation:\n    Salaries: None mentioned.\n    Lab condition: None mentioned.\n\n• -Model Decomposition and Reassembly for Purified Knowledge Transfer in Personalized Federated Learning:\n    Salaries: None mentioned.\n    Lab condition: None mentioned.\n\n• -Personalized Federated Domain-Incremental Learning Based on Adaptive Knowledge Matching:\n    Salaries: None mentioned.\n    Lab condition: None mentioned.\n\n• -Multi-modal Dual-embedding Networks for Malware Open-set Recognition:\n    Salaries: No salary information available in this text.\n    Lab condition: The lab conditions of the researchers are not explicitly mentioned. • -Graph Knows Unknowns: Reformulate Zero-Shot Learning as Sample-Level Graph Recognition, J. Guo, S. Guo, Q. Zhou, Z. Liu, X. Lu, F. Huo,AAAI Conference on Artificial Intelligence(AAAI, CCF-A/Core-A*),2023.\n• -Graph Knows Unknowns: Reformulate Zero-Shot Learning as Sample-Level Graph Recognition,J. Guo#, S. Guo, Q. Zhou, Z. Liu, X. Lu,F. Huo,AAAI Conference on Artificial Intelligence(AAAI, CCF-A/Core-A*),2023.\n• -Decomposed Soft Prompt Guided Fusion Enhancing for Compositional Zero-Shot Learning,X. Lu, S. Guo, Z. Liu,J. Guo#,IEEE/CVF Conference on Computer Vision and Pattern Recognition(CVPR, CCF-A/Core-A*),2023.\n• -Towards Data-Independent Knowledge Transfer in Model-Heterogeneous Federated Learning,J. Zhang, S. Guo,J. Guo#, D. Zeng, J. Zhou, A. Zomaya,IEEE Transactions on Computers(TC, CCF-A, DOI:10.1109/TC.2023.3272801),2023.\n• -UTDNet: A Unified Triplet Decoder Network for Multimodal Salient Object Detection,F. Huo, Z. Liu,J. Guo#, W. Xu, S. Guo,Neural Networks(NN, IF=9.657/JCR-Q1, DOI:10.1016/j.neunet.2023.11.051),2023.\n• -Towards performance-maximizing neural network pruning via global channel attention,Y. Wang, S. Guo,J. Guo, J. Zhang, W. Zhang, C. Yan, Y. Zhang,Neural Networks(NN, IF=9.657/JCR-Q1, DOI:10.1016/j.neunet.2023.11.065),2023.\n• -Hwamei: A Learning-Based Synchronization Scheme for Hierarchical Federated Learning,T. Qi, Y. Zhan, P. Li,J. Guo, Y. Xia,IEEE International Conference on Distributed Computing Systems(ICDCS, CCF-B/Core-A),2023.\n• -Towards Fairer and More Efficient Federated Learning via Multidimensional Personalized Edge Models,Y. Wang,J. Guo, J. Zhang, S. Guo, W. Zhang, Q. Zheng,International Joint Conference on Neural Networks(IJCNN, Core-B),2023.\n \nNote: There is no explicit information about researcher's recruitment information, salary, and lab conditions in the provided text. <salaries not found>\n \n lab conditions:\n- Malware Recognition in an Open-Set Scenario, Z. Liu, S. Guo, J. Guo#, Y. Xu, F. Huo,IEEE Transactions on Multimedia(TMM, IF=8.4/JCR-Q1, DOI:10.1109/TMM.2022.3222657),2022.\n- On-Device Learning Systems for Edge Intelligence: A Software and Hardware Synergy Perspective,Q. Zhou, Z. Qu, S. Guo, B. Luo,J. Guo, Z. Xu, R. Akerkar,IEEE Internet of Things Journal(IoT-J, IF=10.6/JCR-Q1, DOI:10.1109/JIOT.2021.3063147),2021.\n- Dual-View Attention Networks for Single Image Super-Resolution,J. Guo, S. Ma, J. Zhang, Q. Zhou, S. Guo,ACM International Conference on Multimedia(ACM-MM, CCF-A/Core-A*),2020.\n- A Novel Perspective to Zero-Shot Learning: Towards an Alignment of Manifold Structures via Semantic Feature Expansion,J. Guo, S. Guo,IEEE Transactions on Multimedia(TMM, IF=8.4/JCR-Q1, DOI:10.1109/TMM.2020.2984091),2020.\n- Adaptive Adjustment with Semantic Feature Space for Zero-Shot Recognition,J. Guo, S. Guo, IEEE International Conference on Acoustics, Speech, and Signal Processing(ICASSP, CCF-B/Core-B),2019.\n- AMS-SFE: Towards an Alignment of Manifold Structures via Semantic Feature Expansion for Zero-Shot Learning,J. Guo, S. Guo,IEEE International Conference on Multimedia and Expo(ICME, CCF-B/Core-A),2019.\n> Nothing."
}