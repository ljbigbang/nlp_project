[
    {
        "name": "Bo",
        "meta_data": "personal background, education background, research interest, lab",
        "content": "Bo Yang\n\n\n\nI am an Assistant Professor (2020.11-) in the at . I completed my D.Phil degree (2016.10-2020.09)\n                    in the at ,\n                    supervised by Profs. and .\n                    Prior to Oxford, I obtained an M.Phil degree from and a B.Eng degree from . In my D.Phil study, I interned at the Augumented Reality team of (Palo Alto, CA).\n                    In my M.Phil study, I interned at .\n                    In my undergraduate study, I was an exchange student at (Valencia, Spain). \n\n\n\n/ / / \n\n\n\nI lead the ,\n               focusing on the fundamental research problems in machine learning, computer vision, and robotics.\n               Our research goal is to build intelligent systems which endow machines to recover, understand, and eventually interact with the real 3D world.\n               This includes accurate and efficient recognition, segmentation and reconstruction of all individual objects within large-scale 3D scenes."
    },
    {
        "name": "Bo",
        "meta_data": "publication, lab",
        "content": "(All emails/CVs are carefully read and evaluated. Only matched candidates will be responded.)\n\n\n\n[2024.05.23] Our of OGC is accepted by TPAMI 2024.\n\n\n\n[2024.05.02] Our paper is accepted by ICML 2024.\n\n\n\n[2024.01.29] Our paper is accepted by ICRA 2024.\n\n\n\n[2024.01.09] Our paper is accepted by IJCV 2024.\n\n\n\n[2023.09.22] Our papers and are accepted by NeurIPS 2023.\n\n\n\n[2023.03.31] We are going to organize at ICCV 2023.\n\n\n\n[2023.02.28] Our paper is accepted by CVPR 2023.\n\n\n\n[2023.01.22] Our paper is accepted by ICLR 2023.\n\n\n\n[2023.01.18] Our paper is accepted by ICRA 2023.\n\n\n\n[2022.09.03] Our papers and are accepted by NeurIPS 2022.\n\n\n\n[2022.07.03] Our paper is accepted by ECCV 2022.\n\n\n\n[2022.05.26] Our of SpinNet is accepted by TPAMI.\n\n\n\n[2022.05.04] We are going to organize at ECCV 2022.\n\n\n\n[2022.04.19] Our paper is on arXiv.\n\n\n\n[2021.11.11] Our of SensatUrban is accepted by IJCV.\n\n\n\n[2021.07.23] Our paper for neural rendering is accepted by ICCV 2021."
    },
    {
        "name": "Bo",
        "meta_data": "publication, research interest",
        "content": "[2022.04.19] Our paper is on arXiv.\n\n\n\n[2021.11.11] Our of SensatUrban is accepted by IJCV.\n\n\n\n[2021.07.23] Our paper for neural rendering is accepted by ICCV 2021.\n\n\n\n[2021.05.15] Our of RandLA-Net is accepted by TPAMI.\n\n\n\n[2021.04.09] We are going to organize at ICCV 2021.\n\n\n\n[2021.03.01] Our papers and are accepted by CVPR 2021.\n\n\n\n[2021.02.28] Our paper is accepted by ICRA 2021.\n\n\n\n[2020.11.28] We organize a tutorial about at 3DV 2020.\n\n\n\n[2020.02.27] Our paper for 3D semantic segmentation is accepted by CVPR 2020.\n\n\n\n[2019.09.03] Our paper is accepted as a spotlight at NeurIPS 2019.\n\n\n\n[2019.08.16] Our paper is accepted by IJCV.\n\n\n\n\nZ. Song, J. Li, B. Yang \nInternational Conference on Machine Learning (ICML) , 2024\n/ \n\n\n\nWe present the first framework to represent dynamic 3D scenes in infinitely many ways from a monocular RGB video."
    },
    {
        "name": "Bo",
        "meta_data": "publication, research interest",
        "content": "We present the first framework to represent dynamic 3D scenes in infinitely many ways from a monocular RGB video.\n\n\n\n\nZ. Liu, B. Yang* , Y. Luximon, A. Kumar, J. Li\nAdvances in Neural Information Processing Systems (NeurIPS) , 2023\n/ / \n(* indicates corresponding author)\n\n\n\nWe propose a novel ray-based 3D shape representation, achieving a 1000x faster speed in rendering.\n\n\n\n\nJ. Li, Z. Song, B. Yang \nAdvances in Neural Information Processing Systems (NeurIPS) , 2023\n/ We present a novel framework to simultaneously learn the geometry, appearance, and physical velocity of 3D scenes. \n\n\n\nWe present a novel framework to simultaneously learn the geometry, appearance, and physical velocity of 3D scenes.\n\n\n\n\nZ. Zhang, B. Yang* , B. Wang, B. Li\nIEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2023\n/ \n(* indicates corresponding author) We propose the first unsupervised 3D semantic segmentation method, learning from growing superpoints in point clouds."
    },
    {
        "name": "Bo",
        "meta_data": "publication, research interest",
        "content": "We propose the first unsupervised 3D semantic segmentation method, learning from growing superpoints in point clouds.\n\n\n\n\nZ. Song, B. Yang \nAdvances in Neural Information Processing Systems (NeurIPS) , 2022\n/ / We introduce the first unsupervised 3D object segmentation method on point clouds. \n\n\n\nWe introduce the first unsupervised 3D object segmentation method on point clouds.\n\n\n\n\n\nB. Yang\n\n\nThesis committee (Transfer/Confirmation/Viva):\n, , , .\nThis thesis aims to understand scenes and the objects within them by learning general and\n                robust representations using deep neural networks, trained on large-scale real-world 3D data.\n                In particular, the thesis makes three core contributions from object-level 3D shape estimation\n                from single or multiple views to scene-level semantic understanding."
    },
    {
        "name": "Bo",
        "meta_data": "research interest",
        "content": "This thesis aims to understand scenes and the objects within them by learning general and\n                robust representations using deep neural networks, trained on large-scale real-world 3D data.\n                In particular, the thesis makes three core contributions from object-level 3D shape estimation\n                from single or multiple views to scene-level semantic understanding.\n\n\n\n[2023.05] Invited talk about at VALSE webinar.\n\n\n\n[2022.12] Invited talk about at TechBeat forum.\n\n\n\n[2022.06] Invited talk about 3D Scene Reconstruction, Decomposition and Manipulation at Xiamen University.\n\n\n\n[2021.10] Invited talk about at GAMES Webinar.\n\n\n\n[2021.04] Invited talk about at a CSIG workshop.\n\n\n\n[2020.10] Invited talk about 3D Scene Understanding at . Check out the .\n\n\n\n[2020.09] Invited talk about 3D Point Cloud Segmentation at .\n\n\n\n[2020.03] Invited talk about our and at Shenlan.\n                Here are the and ."
    },
    {
        "name": "Bo",
        "meta_data": "[publication, research interest, lab]",
        "content": "[2020.09] Invited talk about 3D Point Cloud Segmentation at .\n\n\n\n[2020.03] Invited talk about our and at Shenlan.\n                Here are the and .\n\n\n\n[2018 -] Regularly reviewing for top-tier conferences/journals in machine learning, computer vision, and robotics.\n\n\n\nFall, 2023 : (The Hong Kong Polytechnic University).\n\n\n\nSpring, 2023 : (The Hong Kong Polytechnic University).\n\n\n\nSpring&Fall, 2021&2022 : (The Hong Kong Polytechnic University).\n\n\n\nHilary, 2019 : (University of Oxford).\n\n\n\nMichaelmas, 2018&2017 : (University of Oxford).\n\n\n\nSpring, 2014 : (The University of Hong Kong).\n\n\n\nQingyong Hu (Oct 2018 - ): Department of Computer Science at University of Oxford.\n\n\n\nAlexander Trevithick (Oct 2019 - Mar 2021): Now PhD at UCSD.\n\n\n\nJianan Wang (May - Dec 2018): Now with .\n\n\n\nZihang Lai (Oct 2017 - Mar 2018): Now PhD at ."
    },
    {
        "name": "Bo",
        "meta_data": "personal background, lab",
        "content": "Alexander Trevithick (Oct 2019 - Mar 2021): Now PhD at UCSD.\n\n\n\nJianan Wang (May - Dec 2018): Now with .\n\n\n\nZihang Lai (Oct 2017 - Mar 2018): Now PhD at .\n\n\n\nIn my free time, I like playing tennis on , , and .\n               I also like to fly drones for landscape photography. Here's a video over the historic Oxford\n               [ , ], and another video for the scenic Lake District\n               [ ]. Remember to turn up the volume for the background music. \n\n\n\nLast update: 2024.09.Thanks."
    }
]